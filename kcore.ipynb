{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import itertools\n",
    "import operator\n",
    "import copy\n",
    "import igraph\n",
    "import heapq\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terms_to_graph(terms, window_size):\n",
    "    '''This function returns a directed, weighted igraph from lists of list of terms (the tokens from the pre-processed text)\n",
    "    e.g., ['quick','brown','fox']\n",
    "    Edges are weighted based on term co-occurence within a sliding window of fixed size 'w'\n",
    "    '''\n",
    "    \n",
    "    from_to = {}\n",
    "\n",
    "    w = min(window_size, len(terms))\n",
    "    # create initial complete graph (first w terms)\n",
    "    terms_temp = terms[0:w]\n",
    "    indexes = list(itertools.combinations(range(w), r=2))\n",
    "\n",
    "    new_edges = []\n",
    "\n",
    "    for my_tuple in indexes:\n",
    "        new_edges.append(tuple([terms_temp[i] for i in my_tuple]))\n",
    "    for new_edge in new_edges:\n",
    "        if new_edge in from_to:\n",
    "            from_to[new_edge] += 1\n",
    "        else:\n",
    "            from_to[new_edge] = 1\n",
    "\n",
    "    # then iterate over the remaining terms\n",
    "    for i in range(w, len(terms)):\n",
    "        # term to consider\n",
    "        considered_term = terms[i]\n",
    "        # all terms within sliding window\n",
    "        terms_temp = terms[(i - w + 1):(i + 1)]\n",
    "\n",
    "        # edges to try\n",
    "        candidate_edges = []\n",
    "        for p in range(w - 1):\n",
    "            candidate_edges.append((terms_temp[p], considered_term))\n",
    "\n",
    "        for try_edge in candidate_edges:\n",
    "\n",
    "            # if not self-edge\n",
    "            if try_edge[1] != try_edge[0]:\n",
    "\n",
    "                # if edge has already been seen, update its weight\n",
    "                if try_edge in from_to:\n",
    "                    from_to[try_edge] += 1\n",
    "\n",
    "                # if edge has never been seen, create it and assign it a unit weight\n",
    "                else:\n",
    "                    from_to[try_edge] = 1\n",
    "\n",
    "    # create empty graph\n",
    "    g = igraph.Graph(directed=True)\n",
    "\n",
    "    # add vertices\n",
    "    g.add_vertices(sorted(set(terms)))\n",
    "\n",
    "    # add edges, direction is preserved since the graph is directed\n",
    "    g.add_edges(list(from_to.keys()))\n",
    "\n",
    "    # set edge and vertice weights\n",
    "    g.es['weight'] = list(from_to.values()) # based on co-occurence within sliding window\n",
    "    g.vs['weight'] = g.strength(weights=list(from_to.values())) # weighted degree\n",
    "\n",
    "    return (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_dec(g,weighted):\n",
    "    '''(un)weighted k-core decomposition'''\n",
    "    # work on clone of g to preserve g \n",
    "    gg = copy.deepcopy(g)\n",
    "    if not weighted:\n",
    "        gg.vs['weight'] = gg.strength() # overwrite the 'weight' vertex attribute with the unweighted degrees\n",
    "    # initialize dictionary that will contain the core numbers\n",
    "    cores_g = dict(zip(gg.vs['name'],[0]*len(gg.vs)))\n",
    "    \n",
    "    while len(gg.vs) > 0:\n",
    "        # find index of lowest degree vertex\n",
    "        min_degree = min(gg.vs['weight'])\n",
    "        index_top = gg.vs['weight'].index(min_degree)\n",
    "        name_top = gg.vs[index_top]['name']\n",
    "        # get names of its neighbors\n",
    "        neighbors = gg.vs[gg.neighbors(index_top)]['name']\n",
    "        # exclude self-edges\n",
    "        neighbors = [elt for elt in neighbors if elt!=name_top]\n",
    "        # set core number of lowest degree vertex as its degree\n",
    "        cores_g[name_top] = min_degree\n",
    "        ### fill the gap (delete top vertex and its incident edges) ###\n",
    "        gg.delete_vertices(index_top)\n",
    "        \n",
    "        if neighbors:\n",
    "            if weighted: \n",
    "                ### fill the gap (compute the new weighted degrees, save results as 'new_degrees')\n",
    "                new_degrees=gg.strength(weights=gg.es['weight'])\n",
    "            else:\n",
    "                ### fill the gap (same as above but for the basic degree) ###\n",
    "                new_degrees=gg.strength()\n",
    "            # iterate over neighbors of top element\n",
    "            for neigh in neighbors:\n",
    "                index_n = gg.vs['name'].index(neigh)\n",
    "                gg.vs[index_n]['weight'] = max(min_degree,new_degrees[index_n])  \n",
    "        \n",
    "    return(cores_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('data_nonstem.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text = list(train.text)\n",
    "list_text = [str.split(str(text)) for text in list_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=[terms_to_graph(keywds,4) for keywds in list_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "425\n",
      "850\n",
      "1275\n",
      "1700\n"
     ]
    }
   ],
   "source": [
    "method_names = ['kc','wkc']\n",
    "keywords = dict(zip(method_names,[[],[]]))\n",
    "\n",
    "for counter,g in enumerate(gs):\n",
    "    # k-core\n",
    "    core_numbers = core_dec(g,False)\n",
    "    max_c_n = max(core_numbers.values())\n",
    "    keywords['kc'].append([kwd for kwd, c_n in core_numbers.items() if c_n == max_c_n])\n",
    "    # weighted k-core\n",
    "    core_numbers = core_dec(g,True)\n",
    "    max_c_n = max(core_numbers.values())\n",
    "    keywords['wkc'].append([kwd for kwd, c_n in core_numbers.items() if c_n == max_c_n])\n",
    "    if counter % round(len(gs)/5) == 0:\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['kc'] = keywords['kc']\n",
    "train['wkc'] = keywords['wkc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data_kcore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
